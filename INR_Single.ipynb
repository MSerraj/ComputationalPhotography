{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.utils import *\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# Autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "\n",
    "image_files = [f for f in os.listdir(data_folder) if f.endswith(\"png\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose a random image to train a neural representation on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random image to train on\n",
    "img_file_path = '0002.png'\n",
    "img_path = os.path.join(data_folder, img_file_path)\n",
    "img_original = Image.open(img_path)\n",
    "\n",
    "# Convert image to numpy array\n",
    "img_np_original = np.array(img_original)\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_np_original)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Original Image: {img_file_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Get image dimensions\n",
    "height_target, width_target, channels = img_np_original.shape\n",
    "print(f\"Image dimensions: {height_target}x{width_target}, {channels} channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will downsize the original image to a smaller resolution using a random integer factor\n",
    "downsize_factor = 3\n",
    "print(f\"Downsize factor: {downsize_factor}\")\n",
    "img_resized = img_original.resize((width_target // downsize_factor, height_target // downsize_factor))\n",
    "\n",
    "# convert image to numpy array\n",
    "img_np_resized = np.array(img_resized)\n",
    "\n",
    "# Display the resized image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_np_resized)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Resized Image: {width_target // downsize_factor}x{height_target // downsize_factor}\")\n",
    "plt.show()\n",
    "\n",
    "# Print the resolution of the new image\n",
    "height_resized, width_resized, channels = img_np_resized.shape\n",
    "print(f\"Resized image dimensions: {height_resized}x{width_resized}, {channels} channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will next normalize the pixels to have values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the resized image\n",
    "img_np_resized_standardized = img_np_resized / 255.0  # Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean of the resized image\n",
    "print(f\"Resized image mean: {np.mean(img_np_resized_standardized, axis=(0, 1))}\")\n",
    "print(f\"Resized image std: {np.std(img_np_resized_standardized, axis=(0, 1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the coordinates of the image to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_coordinates = get_normalized_coordinates(height_resized, width_resized)\n",
    "pixel_values = img_np_resized_standardized.reshape(-1, channels)\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Normalized coordinates shape: {normalized_coordinates.shape}\")\n",
    "print(f\"Pixel values shape: {pixel_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset and dataloader for the downsampled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = ImageDataset(normalized_coordinates, pixel_values)\n",
    "dataloader = DataLoader(dataset, batch_size=4096, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = torch.nn.MSELoss()\n",
    "model = INRModel(input_dim=2, output_dim=channels, hidden_dim=128, num_layers=3, dropout_rate=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "losses = model.train_model(dataloader, num_epochs=100, lr=1e-3, device=device, criterion = criterion, optimizer = optimizer)\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate normalized coordinates for the original image size\n",
    "target_coords_normalized = get_normalized_coordinates(height_target, width_target)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "target_coords_tensor = torch.from_numpy(target_coords_normalized).float().to(device)\n",
    "\n",
    "# Use the trained model to predict the RGB values for these coordinates\n",
    "with torch.no_grad():\n",
    "    pred_pixels = model(target_coords_tensor).cpu().numpy()\n",
    "    \n",
    "print(f\"Max and Min values of pred_pixels: {np.max(pred_pixels)}, {np.min(pred_pixels)}\")\n",
    "\n",
    "# Denormalize the RGB values using the mean and std of the resized image (i.e the training data)\n",
    "reconstructed_img_reshaped_normalized = pred_pixels.reshape(height_target, width_target, channels)\n",
    "# Convert to integer type and denormalize\n",
    "reconstructed_img_reshaped_denormalized = (reconstructed_img_reshaped_normalized * 255).astype(np.uint8)\n",
    "# IMPORTANT: Need to round the pixels to the nearest integer value and clip them to [0, 255] range\n",
    "reconstructed_img_reshaped_denormalized = np.clip(reconstructed_img_reshaped_denormalized, 0, 255)\n",
    "\n",
    "# Display the reconstructed image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(reconstructed_img_reshaped_denormalized)\n",
    "plt.title('Reconstructed Image at Original Size')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Check that the shapes of the reconstructed image and original image are the same\n",
    "\n",
    "print(f\"Downsized image shape: {img_np_resized.shape}\")\n",
    "print(f\"Reconstructed image shape: {reconstructed_img_reshaped_denormalized.shape}\")\n",
    "print(f\"Original image shape: {img_np_original.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
